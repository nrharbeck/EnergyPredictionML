{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RenewableEnergyNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtjnsB9TF8S7DanZGSrs9q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBZq2dafeVVA",
        "outputId": "439d128a-4bc5-4808-be99-9a72dde30b0f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/nrharbeck/EnergyPredictionML/main/DataProcessing/EIA_DSIRE_Data_Tech.csv\")\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Unnamed: 0  ...  No Programs Available_Regulatory Policy\n",
            "0               0  ...                                        0\n",
            "1               1  ...                                        0\n",
            "2               2  ...                                        0\n",
            "3               3  ...                                        0\n",
            "4               4  ...                                        0\n",
            "...           ...  ...                                      ...\n",
            "13590       13590  ...                                        0\n",
            "13591       13591  ...                                        0\n",
            "13592       13592  ...                                        0\n",
            "13593       13593  ...                                        0\n",
            "13594       13594  ...                                        0\n",
            "\n",
            "[13595 rows x 188 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZJweUzmer2P"
      },
      "source": [
        "#Drop any NA rows for model building\n",
        "df = df.dropna(how='any')\n",
        "\n",
        "#Now remove\n",
        "\n",
        "#Remove CO2 emissions\n",
        "df = df[~df.series_id.str.contains(\"EMISS.CO2-TOTV\")]\n",
        "\n",
        "#Make a new column with the EIA generation categories\n",
        "df['generation_energy'] = df['series_id'].str[9:-8]\n",
        "\n",
        "#Guide to see if strings changse from https://stackoverflow.com/questions/40348541/pandas-diff-with-string\n",
        "df['Series_Change'] = df['series_id'].ne(df['series_id'].shift().bfill()).astype(int)\n",
        "df[\"Generation_Diff\"] = np.where(-df['Generation'].diff() > 0, 1, 0) \n",
        "df['Generation_Increase'] = np.where((df[\"Generation_Diff\"] > 0) & (df['Series_Change'] == 0), 1, 0)\n",
        "\n",
        "#Split data into features and target. Descriptive EIA data is removed here.\n",
        "X = df.drop(columns=['Generation', 'Series_Change', 'Generation_Diff', 'Generation_Increase', 'Unnamed: 0', 'Index', 'units', 'Copyright', 'description','end','f','geography','iso3166','name','source','start', 'series_id'])\n",
        "y = df['Generation_Increase']\n",
        "\n",
        "#Encode categorical features\n",
        "#print(X.columns)\n",
        "X = pd.get_dummies(X, columns=['Date','generation_energy','State'])\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Nx6ndYnALv"
      },
      "source": [
        "#Split data into train and test sets. Validation with the training set will be incorporated into the pipeline below\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0f9_uy_Vxoj",
        "outputId": "4f7d0781-18d4-40e5-d24e-9f24122cbe22"
      },
      "source": [
        "#Compare Performance with a Logistic Regression model\n",
        "#Guide from Professor Yuxiao Huang, The George Washinton University\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Implement me\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "print(pd.DataFrame(data=y_train, columns=['Generation_Increase'])['Generation_Increase'].value_counts())\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "clfs = {'lr': LogisticRegression(random_state=0),\n",
        "        'mlp': MLPClassifier(random_state=0),\n",
        "        'dt': DecisionTreeClassifier(random_state=0),\n",
        "        'rf': RandomForestClassifier(random_state=0),\n",
        "        'xgb': XGBClassifier(seed=0)}\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipe_clfs = {}\n",
        "\n",
        "for name, clf in clfs.items():\n",
        "    pipe_clfs[name] = Pipeline([('StandardScaler', StandardScaler()),('clf', clf)])\n",
        "\n",
        "param_grids = {}\n",
        "C_range = [10 ** i for i in range(-4, 5)]\n",
        "\n",
        "#Logistic Regression Parameter Grid\n",
        "param_grid = [{'clf__multi_class': ['ovr'], \n",
        "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "               'clf__C': C_range},\n",
        "              \n",
        "              {'clf__multi_class': ['multinomial'],\n",
        "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
        "               'clf__C': C_range}]\n",
        "\n",
        "param_grids['lr'] = param_grid\n",
        "\n",
        "#MLP Parameter Grid\n",
        "param_grid = [{'clf__hidden_layer_sizes': [10, 100],\n",
        "               'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
        "param_grids['mlp'] = param_grid\n",
        "\n",
        "#Decision Tree Parameter Grid\n",
        "param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
        "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
        "param_grids['dt'] = param_grid\n",
        "\n",
        "#Random Forest Parameter Grid\n",
        "param_grid = [{'clf__n_estimators': [10, 100, 1000],\n",
        "               'clf__min_samples_split': [2, 10, 30],\n",
        "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
        "param_grids['rf'] = param_grid\n",
        "\n",
        "#XGBoost Parameter Grid\n",
        "param_grid = [{'clf__eta': [10 ** i for i in range(-4, 1)],\n",
        "               'clf__gamma': [0, 10, 100],\n",
        "               'clf__lambda': [10 ** i for i in range(-4, 5)]}]\n",
        "param_grids['xgb'] = param_grid\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# The list of [best_score_, best_params_, best_estimator_]\n",
        "best_score_param_estimators = []\n",
        "\n",
        "# For each classifier\n",
        "for name in pipe_clfs.keys():\n",
        "    # GridSearchCV\n",
        "    gs = GridSearchCV(estimator=pipe_clfs[name],\n",
        "                      param_grid=param_grids[name],\n",
        "                      scoring='accuracy',\n",
        "                      n_jobs=1,\n",
        "                      iid=False,\n",
        "                      cv=StratifiedKFold(n_splits=10,\n",
        "                                         shuffle=True,\n",
        "                                         random_state=0))\n",
        "    # Fit the pipeline\n",
        "    gs = gs.fit(X_train, y_train)\n",
        "    \n",
        "    # Update best_score_param_estimators\n",
        "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
        "\n",
        "# Sort best_score_param_estimators in descending order of the best_score_\n",
        "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
        "\n",
        "# For each [best_score_, best_params_, best_estimator_]\n",
        "for best_score_param_estimator in best_score_param_estimators:\n",
        "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
        "    # Since we only print out the type of classifier of the pipeline\n",
        "    print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    5017\n",
            "0    4334\n",
            "Name: Generation_Increase, dtype: int64\n",
            "[0.6622822112527995, {'clf__eta': 0.0001, 'clf__gamma': 0, 'clf__lambda': 0.0001}, <class 'xgboost.sklearn.XGBClassifier'>]\n",
            "\n",
            "[0.6585361533890947, {'clf__activation': 'logistic', 'clf__hidden_layer_sizes': 100}, <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>]\n",
            "\n",
            "[0.658110288404406, {'clf__C': 0.1, 'clf__multi_class': 'ovr', 'clf__solver': 'saga'}, <class 'sklearn.linear_model._logistic.LogisticRegression'>]\n",
            "\n",
            "[0.6358670414552767, {'clf__min_samples_leaf': 30, 'clf__min_samples_split': 2, 'clf__n_estimators': 1000}, <class 'sklearn.ensemble._forest.RandomForestClassifier'>]\n",
            "\n",
            "[0.6349052744640981, {'clf__min_samples_leaf': 30, 'clf__min_samples_split': 2}, <class 'sklearn.tree._classes.DecisionTreeClassifier'>]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdMfijGd6mro",
        "outputId": "365e7bcd-62f8-4d2a-a0df-e19b445bdb83"
      },
      "source": [
        "y_pred = best_score_param_estimators[1][2].predict(X_test)\n",
        "print(y_pred)\n",
        "print(np.array(y_test))\n",
        "print(\"Accuracy on the test set:\", round((1-(np.abs(y_pred - y_test).sum()/len(y_pred)))*100,8),\"percent\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 ... 1 0 1]\n",
            "[0 0 0 ... 1 0 1]\n",
            "Accuracy on the test set: 65.78272027 percent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlrRKw6WmZq5",
        "outputId": "b196be92-8cbd-441a-904c-0dfb4d9ba301"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "#Set up cross validation with guide from https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=3, shuffle=True)\n",
        "acc_per_fold =[]\n",
        "loss_per_fold = []\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "\"\"\"\n",
        "for train, val in kfold.split(X_train, y_train):\n",
        "\n",
        "  # define model\n",
        "  hidden_layers = 3\n",
        "  model = Sequential()\n",
        "  model.add(Dense(100, activation='sigmoid', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "  for layer in range(hidden_layers):\n",
        "    model.add(Dense(30, activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(X_train.iloc[train], y_train.iloc[train],\n",
        "              batch_size=32,\n",
        "              epochs=150,\n",
        "              verbose=0)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X_train.iloc[val], y_train.iloc[val], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\"\"\"  \n",
        "# define model without cross validation\n",
        "hidden_layers = 3\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='sigmoid', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "for layer in range(hidden_layers):\n",
        "  model.add(Dense(30, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=0)\n",
        "# Generate generalization metrics\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "acc_per_fold.append(scores[1] * 100)\n",
        "loss_per_fold.append(scores[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for fold 1: loss of 1.3033943176269531; accuracy of 62.01881766319275%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLlL0rre1eod",
        "outputId": "0147bff5-60ba-46b7-f7e6-4cc9f997b0ba"
      },
      "source": [
        "# evaluate the model\n",
        "error_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "error = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print('Training set accuracy: %.3f percent' % (error_train[1]*100))\n",
        "print('Test set accuracy: %.3f percent' % (error[1]*100))\n",
        "\n",
        "# make a prediction\n",
        "yhat = model.predict(X_test)\n",
        "print(\"Accuracy on the test set:\", round((1-(np.abs(((yhat>0.50)*1).reshape(1,-1) - np.array(y_test).reshape(1,-1)).sum()/len(y_test)))*100,8),\"percent\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy: 78.676 percent\n",
            "Test set accuracy: 62.019 percent\n",
            "Accuracy on the test set: 62.0188195 percent\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}